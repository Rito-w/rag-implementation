#!/usr/bin/env python3
"""
Self-RAGæµ‹è¯•å’ŒéªŒè¯æ–¹æ¡ˆ

æµ‹è¯•Self-RAGåŸºçº¿æ–¹æ³•çš„å„ä¸ªç»„ä»¶å’Œæ•´ä½“åŠŸèƒ½ï¼Œ
ç¡®ä¿å®ç°æ­£ç¡®æ€§å’Œæ€§èƒ½è¡¨ç°ã€‚
"""

import os
import sys
import time
import json
from pathlib import Path
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def test_retrieval_decider():
    """æµ‹è¯•æ£€ç´¢å†³ç­–å™¨"""
    print("ğŸ§ª æµ‹è¯•æ£€ç´¢å†³ç­–å™¨...")
    
    from src.baselines.self_rag import RetrievalDecider
    
    decider = RetrievalDecider()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "query": "What is machine learning?",
            "expected_retrieve": True,
            "description": "äº‹å®æ€§æŸ¥è¯¢ï¼Œåº”è¯¥æ£€ç´¢"
        },
        {
            "query": "Hello, how are you?",
            "expected_retrieve": False,
            "description": "ç®€å•é—®å€™ï¼Œä¸éœ€è¦æ£€ç´¢"
        },
        {
            "query": "Compare the advantages and disadvantages of neural networks versus traditional algorithms",
            "expected_retrieve": True,
            "description": "å¤æ‚å¯¹æ¯”æŸ¥è¯¢ï¼Œåº”è¯¥æ£€ç´¢"
        },
        {
            "query": "What is the capital of France?",
            "expected_retrieve": True,
            "description": "å…·ä½“äº‹å®æŸ¥è¯¢ï¼Œåº”è¯¥æ£€ç´¢"
        },
        {
            "query": "I think it's a nice day",
            "expected_retrieve": False,
            "description": "ä¸»è§‚è¡¨è¾¾ï¼Œä¸éœ€è¦æ£€ç´¢"
        }
    ]
    
    results = []
    for i, case in enumerate(test_cases, 1):
        decision = decider.decide(case["query"])
        
        correct = decision.should_retrieve == case["expected_retrieve"]
        status = "âœ…" if correct else "âŒ"
        
        print(f"  {i}. {status} {case['description']}")
        print(f"     æŸ¥è¯¢: {case['query']}")
        print(f"     å†³ç­–: {decision.token} (ç½®ä¿¡åº¦: {decision.confidence:.3f})")
        print(f"     æ¨ç†: {decision.reasoning}")
        print()
        
        results.append({
            "case": case,
            "decision": decision.__dict__,
            "correct": correct
        })
    
    accuracy = sum(1 for r in results if r["correct"]) / len(results)
    print(f"ğŸ“Š æ£€ç´¢å†³ç­–å™¨å‡†ç¡®ç‡: {accuracy:.1%}")
    
    return results


def test_relevance_evaluator():
    """æµ‹è¯•ç›¸å…³æ€§è¯„ä¼°å™¨"""
    print("ğŸ§ª æµ‹è¯•ç›¸å…³æ€§è¯„ä¼°å™¨...")
    
    from src.baselines.self_rag import RelevanceEvaluator
    
    evaluator = RelevanceEvaluator()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "query": "What is machine learning?",
            "document": "Machine learning is a subset of artificial intelligence that enables computers to learn and make decisions from data without being explicitly programmed.",
            "expected_relevant": True,
            "description": "é«˜åº¦ç›¸å…³çš„æ–‡æ¡£"
        },
        {
            "query": "What is machine learning?",
            "document": "The weather today is sunny and warm. It's a great day for outdoor activities.",
            "expected_relevant": False,
            "description": "å®Œå…¨ä¸ç›¸å…³çš„æ–‡æ¡£"
        },
        {
            "query": "How do neural networks work?",
            "document": "Neural networks are computational models inspired by biological neural networks. They consist of interconnected nodes that process information.",
            "expected_relevant": True,
            "description": "ç›¸å…³çš„æŠ€æœ¯æ–‡æ¡£"
        }
    ]
    
    results = []
    for i, case in enumerate(test_cases, 1):
        assessment = evaluator.evaluate(case["query"], case["document"])
        
        correct = assessment.is_relevant == case["expected_relevant"]
        status = "âœ…" if correct else "âŒ"
        
        print(f"  {i}. {status} {case['description']}")
        print(f"     ç›¸å…³æ€§: {assessment.token} (åˆ†æ•°: {assessment.relevance_score:.3f})")
        print(f"     è¯­ä¹‰: {assessment.semantic_score:.3f}, å…³é”®è¯: {assessment.keyword_score:.3f}")
        print()
        
        results.append({
            "case": case,
            "assessment": assessment.__dict__,
            "correct": correct
        })
    
    accuracy = sum(1 for r in results if r["correct"]) / len(results)
    print(f"ğŸ“Š ç›¸å…³æ€§è¯„ä¼°å™¨å‡†ç¡®ç‡: {accuracy:.1%}")
    
    return results


def test_quality_evaluator():
    """æµ‹è¯•è´¨é‡è¯„ä¼°å™¨"""
    print("ğŸ§ª æµ‹è¯•è´¨é‡è¯„ä¼°å™¨...")
    
    from src.baselines.self_rag import QualityEvaluator
    
    evaluator = QualityEvaluator()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "query": "What is machine learning?",
            "documents": [
                {"content": "Machine learning is a subset of AI that enables computers to learn from data."}
            ],
            "answer": "Machine learning is a subset of AI that enables computers to learn from data.",
            "description": "å®Œå…¨æ”¯æŒçš„ç­”æ¡ˆ"
        },
        {
            "query": "What is the capital of France?",
            "documents": [
                {"content": "France is a country in Europe with many beautiful cities."}
            ],
            "answer": "The capital of France is Paris.",
            "description": "éƒ¨åˆ†æ”¯æŒçš„ç­”æ¡ˆ"
        },
        {
            "query": "What is quantum computing?",
            "documents": [],
            "answer": "Quantum computing uses quantum mechanics principles.",
            "description": "æ— æ–‡æ¡£æ”¯æŒçš„ç­”æ¡ˆ"
        }
    ]
    
    results = []
    for i, case in enumerate(test_cases, 1):
        assessment = evaluator.evaluate(case["query"], case["documents"], case["answer"])
        
        print(f"  {i}. {case['description']}")
        print(f"     æ”¯æŒåº¦: {assessment.support_assessment.support_level} (åˆ†æ•°: {assessment.support_assessment.support_score:.3f})")
        print(f"     æœ‰ç”¨æ€§: {assessment.usefulness_assessment.token} (åˆ†æ•°: {assessment.usefulness_assessment.usefulness_score:.3f})")
        print(f"     æ•´ä½“è´¨é‡: {assessment.overall_quality:.3f}")
        print()
        
        results.append({
            "case": case,
            "assessment": {
                "support": assessment.support_assessment.__dict__,
                "usefulness": assessment.usefulness_assessment.__dict__,
                "overall": assessment.overall_quality
            }
        })
    
    return results


def test_self_rag_integration():
    """æµ‹è¯•Self-RAGæ•´ä½“é›†æˆ"""
    print("ğŸ§ª æµ‹è¯•Self-RAGæ•´ä½“é›†æˆ...")
    
    try:
        from src.baselines.self_rag import SelfRag
        
        # åˆå§‹åŒ–Self-RAG
        config = {
            "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
            "retriever": {
                "model_name": "sentence-transformers/all-MiniLM-L6-v2",
                "max_docs": 5
            }
        }
        
        self_rag = SelfRag(config)
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "What is machine learning?",
            "How do neural networks work?",
            "Compare supervised and unsupervised learning",
            "Hello, how are you?",
            "What is the weather like today?"
        ]
        
        results = []
        for i, query in enumerate(test_queries, 1):
            print(f"  {i}. æµ‹è¯•æŸ¥è¯¢: {query}")
            
            start_time = time.time()
            result = self_rag.process_query(query)
            processing_time = time.time() - start_time
            
            success = "âœ…" if result.success else "âŒ"
            print(f"     çŠ¶æ€: {success}")
            print(f"     å¤„ç†æ—¶é—´: {processing_time:.3f}ç§’")
            print(f"     ç½®ä¿¡åº¦: {result.overall_confidence:.3f}")
            print(f"     ç­”æ¡ˆé•¿åº¦: {len(result.answer)}å­—ç¬¦")
            
            if result.explanation:
                tokens = result.explanation.get("reflection_tokens", [])
                print(f"     åæ€ä»¤ç‰Œ: {tokens}")
            
            print()
            
            results.append({
                "query": query,
                "result": {
                    "success": result.success,
                    "processing_time": processing_time,
                    "confidence": result.overall_confidence,
                    "answer_length": len(result.answer),
                    "reflection_tokens": result.explanation.get("reflection_tokens", []) if result.explanation else []
                }
            })
        
        # ç»Ÿè®¡ç»“æœ
        success_rate = sum(1 for r in results if r["result"]["success"]) / len(results)
        avg_time = sum(r["result"]["processing_time"] for r in results) / len(results)
        avg_confidence = sum(r["result"]["confidence"] for r in results) / len(results)
        
        print(f"ğŸ“Š Self-RAGæ•´ä½“æµ‹è¯•ç»“æœ:")
        print(f"   æˆåŠŸç‡: {success_rate:.1%}")
        print(f"   å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f}ç§’")
        print(f"   å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        
        return results
        
    except Exception as e:
        print(f"âŒ Self-RAGé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return []


def run_comprehensive_test():
    """è¿è¡Œç»¼åˆæµ‹è¯•"""
    print("ğŸš€ Self-RAGç»¼åˆæµ‹è¯•")
    print("=" * 60)
    
    test_results = {}
    
    # 1. æµ‹è¯•æ£€ç´¢å†³ç­–å™¨
    test_results["retrieval_decider"] = test_retrieval_decider()
    
    print("-" * 60)
    
    # 2. æµ‹è¯•ç›¸å…³æ€§è¯„ä¼°å™¨
    test_results["relevance_evaluator"] = test_relevance_evaluator()
    
    print("-" * 60)
    
    # 3. æµ‹è¯•è´¨é‡è¯„ä¼°å™¨
    test_results["quality_evaluator"] = test_quality_evaluator()
    
    print("-" * 60)
    
    # 4. æµ‹è¯•æ•´ä½“é›†æˆ
    test_results["integration"] = test_self_rag_integration()
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    results_file = "experiments/self_rag_test_results.json"
    os.makedirs("experiments", exist_ok=True)
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(test_results, f, indent=2, ensure_ascii=False, default=str)
    
    print("=" * 60)
    print(f"âœ… ç»¼åˆæµ‹è¯•å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    return test_results


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª Self-RAGæµ‹è¯•å’ŒéªŒè¯ç³»ç»Ÿ")
    print("=" * 60)
    
    # è¿è¡Œç»¼åˆæµ‹è¯•
    results = run_comprehensive_test()
    
    print("\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
    print("1. âœ… æ£€ç´¢å†³ç­–å™¨ï¼šåŸºäºè§„åˆ™çš„æ™ºèƒ½æ£€ç´¢å†³ç­–")
    print("2. âœ… ç›¸å…³æ€§è¯„ä¼°å™¨ï¼šå¤šç»´åº¦æ–‡æ¡£ç›¸å…³æ€§è¯„ä¼°")
    print("3. âœ… è´¨é‡è¯„ä¼°å™¨ï¼šç­”æ¡ˆæ”¯æŒåº¦å’Œæœ‰ç”¨æ€§è¯„ä¼°")
    print("4. âœ… æ•´ä½“é›†æˆï¼šå®Œæ•´çš„Self-RAGå¤„ç†æµç¨‹")
    
    print(f"\nğŸ¯ Self-RAGåŸºçº¿æ–¹æ³•å®ç°å®Œæˆï¼")
    print(f"   å¯ä»¥å¼€å§‹ä¸æˆ‘ä»¬çš„æ™ºèƒ½è‡ªé€‚åº”RAGç³»ç»Ÿè¿›è¡Œå¯¹æ¯”å®éªŒã€‚")


if __name__ == "__main__":
    main()
